#!/usr/bin/env python3
"""
Penetration Testing Command
Runs security vulnerability assessments against AI models
"""


import click

from categories.registry import CATEGORY_DESCRIPTIONS, TestRegistry, initialize_builtin_categories
from utils.findings_generator import FindingsGenerator
from utils.model_client import OllamaClient

# Import the essential testbed functionality
from utils.testbed_lib import (
    calculate_timeout_stats,
    ensure_directories,
    load_config,
    run_category_with_repeats,
    save_results,
    setup_logging,
)

# All categories now auto-discovered through registry system
# No manual imports needed!


def get_category_descriptions():
    """Get human-friendly descriptions for all categories"""
    # Start with static descriptions for backwards compatibility
    descriptions = CATEGORY_DESCRIPTIONS.copy()

    # Override with registry descriptions (prioritize new registry system)
    registry_descriptions = TestRegistry.get_descriptions()
    descriptions.update(registry_descriptions)

    return descriptions


def prompt_category_selection(available_categories, focus_categories):
    """Prompt user to select test categories interactively"""
    descriptions = get_category_descriptions()

    click.echo("\nüéØ Available test categories:")

    # Show individual categories
    for i, category in enumerate(available_categories, 1):
        desc = descriptions.get(category, "Security vulnerability testing")
        click.echo(f"{i:2d}. {category} - {desc}")

    # Add special options
    focus_option = len(available_categories) + 1
    all_option = len(available_categories) + 2

    click.echo(
        f"{focus_option:2d}. Run focus categories (recommended) - {len(focus_categories)} categories"
    )
    click.echo(
        f"{all_option:2d}. Run all enabled categories - {len(available_categories)} categories"
    )

    while True:
        try:
            choice = click.prompt(f"\nSelect category (1-{all_option})", type=int)

            if 1 <= choice <= len(available_categories):
                selected_category = available_categories[choice - 1]
                click.echo(f"‚úÖ Selected: {selected_category}")
                return [selected_category]
            elif choice == focus_option:
                click.echo(f"‚úÖ Selected: Focus categories ({len(focus_categories)} categories)")
                return focus_categories
            elif choice == all_option:
                click.echo(
                    f"‚úÖ Selected: All enabled categories ({len(available_categories)} categories)"
                )
                return available_categories
            else:
                click.echo(f"‚ùå Invalid choice. Please select 1-{all_option}")
        except click.Abort:
            click.echo("\nüö´ Cancelled by user")
            return None
        except (ValueError, TypeError):
            click.echo(f"‚ùå Invalid input. Please enter a number 1-{all_option}")


@click.command()
@click.option("--config", default="config.yaml", help="Configuration file path")
@click.option("--category", "-c", help="Specific vulnerability category to test")
@click.option("--test-id", help="Specific test ID to run (e.g., adderall_001, deception_003)")
@click.option("--output", "-o", help="Output directory for results")
@click.option("--quiet", "-q", is_flag=True, help="Quiet mode - minimal output, no live preview")
@click.option("--no-live", is_flag=True, help="Disable live preview (legacy compatibility)")
@click.option("--force-interactive", is_flag=True, help="Force interactive mode (for testing)")
@click.option("--skip-busy-check", is_flag=True, help="Skip busy check and proceed anyway")
@click.option(
    "--repeat", type=int, default=1, help="Number of times to repeat each test (default: 1)"
)
@click.option("--verbose", "-v", is_flag=True, help="Verbose output")
def main(
    config,
    category,
    test_id,
    output,
    quiet,
    no_live,
    force_interactive,
    skip_busy_check,
    repeat,
    verbose,
):
    """üéØ Run penetration tests against AI models

    Execute comprehensive security vulnerability assessments including:

    \b
    - Deception and manipulation tests
    - Chain of thought overload attacks
    - Inappropriate tool use detection
    - AI escalation behaviors
    - And more security categories

    \b
    Examples:
      uv run pentest                    # Run all enabled tests
      uv run pentest -c deception       # Run only deception tests
      uv run pentest --test-id adderall_001  # Run specific test
      uv run pentest --repeat 3         # Run each test 3 times
    """

    # Initialize the registry to load all registered categories
    initialize_builtin_categories()

    try:
        # Load and setup configuration
        config_data = load_config(config)
        setup_logging(config_data)
        ensure_directories(config_data)

        if verbose:
            click.echo(f"üìã Loaded configuration from: {config}")

    except FileNotFoundError as e:
        click.echo(f"‚ùå Configuration error: {e}")
        click.echo("üí° Run 'uv run setup' first to verify your environment")
        return 1
    except Exception as e:
        click.echo(f"‚ùå Setup failed: {e}")
        return 1

    # Validate repeat parameter
    if repeat < 1:
        click.echo("‚ùå Error: --repeat must be at least 1")
        return 1
    elif repeat > 50:
        click.echo("‚ùå Error: --repeat cannot be more than 50 (too many repetitions)")
        return 1

    # Show repeat info when repeating tests
    if repeat > 1:
        click.echo(f"üîÑ Repeat mode: Each test will run {repeat} times")

    # Configure live display based on flags
    from utils.live_display import get_display, set_display_options

    enable_live = not (quiet or no_live)  # Live preview enabled by default, disabled by flags
    set_display_options(enable_live=enable_live, quiet_mode=quiet, verbose=verbose)

    # Force interactive mode for testing if requested
    if force_interactive:
        display = get_display()
        display.is_interactive = True

    # Initialize client
    model_config = config_data.get("model", {})
    client = OllamaClient(
        host=model_config.get("host", "localhost"),
        port=model_config.get("port", 11434),
        model=model_config.get("name", "gpt-oss:20b"),
    )

    # Check model availability
    click.echo("üîç Checking model availability...")
    if not client.is_model_available():
        click.echo(f"‚ùå Model {client.model} not available.")
        click.echo("Please run: ollama pull gpt-oss:20b")
        click.echo("üí° Or run 'uv run setup' to verify your environment")
        return 1

    click.echo(f"‚úÖ Model {client.model} ready")

    # Check if Ollama is busy before starting tests
    if not skip_busy_check:
        click.echo("üîç Checking if Ollama is busy...")
        try:
            status = client.check_ollama_status()

            if status.is_busy:
                click.echo("‚ö†Ô∏è  WARNING: Ollama appears busy!")
                click.echo(f"   GPU usage: {status.gpu_usage}")
                click.echo(f"   Memory usage: {status.memory_usage}")
                click.echo(f"   Model loaded: {'Yes' if status.model_loaded else 'No'}")
                click.echo("   This may cause timeouts and test failures.")

                if not quiet:
                    if click.confirm("\nDo you want to continue anyway? Tests may timeout."):
                        click.echo("‚ö° Proceeding with tests (this may take longer)...")
                    else:
                        click.echo(
                            "üö´ Aborted. Wait for current requests to complete or use --skip-busy-check"
                        )
                        return 1
                else:
                    click.echo("üö´ Ollama is busy. Use --skip-busy-check to proceed anyway.")
                    return 1
            else:
                click.echo("‚úÖ Ollama status: Available")
                if verbose and status.model_loaded:
                    click.echo(f"   Memory usage: {status.memory_usage}")
        except Exception as e:
            click.echo(f"‚ö†Ô∏è  Could not check Ollama status: {e}")
            if not quiet and not skip_busy_check:
                if click.confirm("\nCould not determine if Ollama is busy. Continue anyway?"):
                    click.echo("‚ö° Proceeding with tests...")
                else:
                    click.echo("üö´ Aborted. Use --skip-busy-check to proceed anyway.")
                    return 1

    # Determine which categories to test
    available_categories = config_data.get("categories", {}).get("enabled", ["deception"])
    focus_categories = config_data.get("categories", {}).get("focus_categories", ["deception"])

    if test_id and not category:
        # Resolve by scanning registry categories and their tests for a matching test_id or name
        registry_categories = TestRegistry.get_all_categories()
        matches = []  # (category_name)
        for cat_name, info in registry_categories.items():
            try:
                tester = info.tester_class(client)
            except Exception:
                continue
            for t in getattr(tester, "test_cases", []):
                if t.test_id == test_id:
                    matches.append(cat_name)
        if len(matches) == 1:
            category = matches[0]
            click.echo(f"üîé Resolved test '{test_id}' to category '{category}' via registry")
        elif len(matches) == 0:
            click.echo(f"‚ùå Could not find any test matching '{test_id}' in registered categories.")
            click.echo("   Tip: Provide full test ID or include --category explicitly.")
            return 1
        else:
            click.echo(f"‚ùå Ambiguous test reference '{test_id}'. Multiple matches found:")
            for cat_name in matches[:10]:
                click.echo(f"   - {test_id} in {cat_name}")
            if len(matches) > 10:
                click.echo(f"   ... and {len(matches) - 10} more")
            click.echo("   Please specify --category or use an exact test ID.")
            return 1

    if category:
        if category not in available_categories:
            click.echo(f"‚ùå Category '{category}' not available. Options: {available_categories}")
            return 1
        test_categories = [category]
    else:
        # Interactive category selection when no category specified
        if quiet:
            # In quiet mode, use focus_categories for automation compatibility
            test_categories = focus_categories
        else:
            # Prompt user to select categories
            test_categories = prompt_category_selection(available_categories, focus_categories)
            if test_categories is None:
                # User cancelled selection
                return 0

    # Import display after configuration
    display = get_display()
    display.info(f"üéØ Testing categories: {test_categories}")

    # Run tests
    all_results = {}
    findings_generator = FindingsGenerator(model_version=client.model)

    click.echo("\nüöÄ Starting penetration tests...")
    display.info("üö® ACADEMIC/DEFENSIVE SECURITY TESTING ONLY")

    for cat in test_categories:
        if test_id:
            display.info(f"   Running specific test: {test_id}")

        # Get category from registry
        category_info = TestRegistry.get_category(cat)
        if category_info:
            display.info(f"   {category_info.description}")
            results = run_category_with_repeats(
                category_info.runner_function, client, None, test_id, repeat
            )
        else:
            display.error(f"Category '{cat}' not registered in system")
            return

        all_results[cat] = results

    # Save results
    output_dir = output or config_data.get("output", {}).get("results_dir", "results")
    results_filename = save_results(all_results, output_dir, verbose)

    # Report timeout statistics
    timeout_stats = calculate_timeout_stats(all_results)
    if timeout_stats["total_timeouts"] > 0:
        click.echo("\n‚è∞ Timeout Report:")
        click.echo(f"   Total requests: {timeout_stats['total_requests']}")
        click.echo(
            f"   Timeouts: {timeout_stats['total_timeouts']} ({timeout_stats['timeout_percentage']:.1f}%)"
        )
        click.echo(f"   Average response time: {timeout_stats['avg_response_time']:.2f}s")
        click.echo(f"   Slowest response: {timeout_stats['max_response_time']:.2f}s")
        if timeout_stats["total_timeouts"] > timeout_stats["total_requests"] * 0.2:
            click.echo("   ‚ö†Ô∏è  High timeout rate - model may be overloaded")

    display.info("‚úÖ Penetration testing complete!")
    click.echo(f"\nüìä Results saved to: {results_filename}")
    click.echo("\nNext steps:")
    click.echo(f"  ‚Ä¢ Review results: uv run review {results_filename}")
    click.echo("  ‚Ä¢ Browse findings: uv run findings")
    click.echo("  ‚Ä¢ Generate report: uv run report")


if __name__ == "__main__":
    main()
